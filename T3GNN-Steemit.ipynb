{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76e04ce",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d94c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, GRUCell\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import roc_auc_score,average_precision_score\n",
    "\n",
    "import random\n",
    "\n",
    "import bisect \n",
    "\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torch_geometric.utils import negative_sampling, erdos_renyi_graph, shuffle_node, to_networkx\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.transforms import SVDFeatureReduction\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.transforms import RandomLinkSplit,NormalizeFeatures,Constant,OneHotDegree\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import GCNConv,SAGEConv,GATv2Conv, GINConv, Linear\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315305df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8b40a",
   "metadata": {},
   "source": [
    "# LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d8f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from steemitdata import get_steemit_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502cf464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snapshots with constant encoder as node features\n",
    "#Snapshots with textual features as node features\n",
    "\n",
    "snapshots_c = get_steemit_dataset(preprocess='constant')\n",
    "snapshots_t = get_steemit_dataset(preprocess='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(snapshots_t)):\n",
    "    torch.save(snapshots_t[i].x, f'steemit-t3gnn-data/{i}_x.pt')\n",
    "    torch.save(snapshots_t[i].edge_index, f'steemit-t3gnn-data/{i}_edge_index.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snapshots with random features as node features\n",
    "snapshots_ts = get_steemit_dataset(preprocess='constant')\n",
    "for snap in snapshots_ts:\n",
    "    snap.x = torch.randn(snap.num_nodes, 384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff34ed04",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9262266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from t3gnn import T3GConvGRU, T3EvolveGCNH, T3EvolveGCNO, T3GNN, T3MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roland_test(model, test_data, data, isnap, device='cpu'):\n",
    "    model.eval()\n",
    "\n",
    "    test_data = test_data.to(device)\n",
    "\n",
    "    h, _ = model(test_data.x, test_data.edge_index, edge_label_index = test_data.edge_label_index, isnap=isnap)\n",
    "    \n",
    "    pred_cont_link = torch.sigmoid(h).cpu().detach().numpy()\n",
    "    \n",
    "    label_link = test_data.edge_label.cpu().detach().numpy()\n",
    "      \n",
    "    avgpr_score_link = average_precision_score(label_link, pred_cont_link)\n",
    "    \n",
    "    return avgpr_score_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ev_test(model, test_data, data, device='cpu'): \n",
    "    model.eval()\n",
    "    test_data = test_data.to(device)\n",
    "    h = model(test_data.x, test_data.edge_index, test_data.edge_label_index)\n",
    "    pred_cont = torch.sigmoid(h).cpu().detach().numpy()\n",
    "    label = test_data.edge_label.cpu().detach().numpy()\n",
    "    avgpr_score = average_precision_score(label, pred_cont)\n",
    "    return avgpr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcgru_test(model, test_data, data, device='cpu'):\n",
    "    model.eval()\n",
    "    test_data = test_data.to(device)\n",
    "    h, _ = model(test_data.x, test_data.edge_index, test_data.edge_label_index)\n",
    "    pred_cont = torch.sigmoid(h).cpu().detach().numpy()\n",
    "    label = test_data.edge_label.cpu().detach().numpy()\n",
    "    avgpr_score = average_precision_score(label, pred_cont)\n",
    "    return avgpr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c87220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "def roland_train_single_snapshot(model, data, train_data, val_data, test_data, isnap,\\\n",
    "                          last_embeddings, optimizer, device='cpu', num_epochs=50, verbose=False):\n",
    "    \n",
    "    avgpr_val_max = 0\n",
    "    best_model = model\n",
    "    train_data = train_data.to(device)\n",
    "    best_epoch = -1\n",
    "    best_current_embeddings = []\n",
    "    \n",
    "    avgpr_trains = []\n",
    "    #avgpr_vals = []\n",
    "    avgpr_tests = []\n",
    "    \n",
    "    tol = 1\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        ## Note\n",
    "        ## 1. Zero grad the optimizer\n",
    "        ## 2. Compute loss and backpropagate\n",
    "        ## 3. Update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred,\\\n",
    "        current_embeddings =\\\n",
    "            model(train_data.x, train_data.edge_index, edge_label_index = train_data.edge_label_index,\\\n",
    "                  isnap=isnap, previous_embeddings=last_embeddings)\n",
    "        \n",
    "        loss = model.loss(pred, train_data.edge_label.type_as(pred)) #loss to fine tune on current snapshot\n",
    "\n",
    "        loss.backward(retain_graph=True)  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "        log = 'Epoch: {:03d}\\n AVGPR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n MRR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n F1-Score Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n Loss: {}'\n",
    "        avgpr_score_val  = roland_test(model, val_data, data, isnap, device)\n",
    "        \n",
    "        #avgpr_trains.append(avgpr_score_train)\n",
    "        #avgpr_vals.append(avgpr_score_val)\n",
    "        #avgpr_tests.append(avgpr_score_test)\n",
    "        \n",
    "        #mrr_trains.append(mrr_train)\n",
    "        #mrr_vals.append(mrr_val)\n",
    "        #mrr_tests.append(mrr_test)\n",
    "        \n",
    "        if avgpr_val_max-tol <= avgpr_score_val:\n",
    "            avgpr_val_max = avgpr_score_val\n",
    "            best_epoch = epoch\n",
    "            best_current_embeddings = current_embeddings\n",
    "            best_model = model\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        \n",
    "    #avgpr_score_train = roland_test(model, train_data, data, isnap, device)\n",
    "    avgpr_score_test = roland_test(model, test_data, data, isnap, device)\n",
    "            \n",
    "    if verbose:\n",
    "        print(f'Best Epoch: {best_epoch}')\n",
    "    #print(f'Best Epoch: {best_epoch}')\n",
    "    \n",
    "    return best_model, optimizer, avgpr_score_test, best_current_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e1e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'num_gnn_layers': [1,2,3],\n",
    "    'update': ['gru','mlp','linrnn','average'],\n",
    "    'hidden_dim': [32, 64, 128, 256, 512],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcgru_train_single_snapshot(model, data, train_data, val_data, test_data,\\\n",
    "                          optimizer, H=None, device='cpu', num_epochs=50, verbose=False):\n",
    "    \n",
    "    mrr_val_max = 0\n",
    "    avgpr_val_max = 0\n",
    "    best_model = model\n",
    "    train_data = train_data.to(device)\n",
    "    best_epoch = -1\n",
    "    \n",
    "    tol = 5e-2\n",
    "    \n",
    "    best_H = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        ## Note\n",
    "        ## 1. Zero grad the optimizer\n",
    "        ## 2. Compute loss and backpropagate\n",
    "        ## 3. Update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #H = None\n",
    "            \n",
    "        pred, H = model(train_data.x, train_data.edge_index, train_data.edge_label_index, H)\n",
    "        \n",
    "        loss = model.loss(pred, train_data.edge_label.type_as(pred)) #loss to fine tune on current snapshot\n",
    "\n",
    "        loss.backward(retain_graph=True)  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "        log = 'Epoch: {:03d}\\n AVGPR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n MRR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n F1-Score Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n Loss: {}'\n",
    "        avgpr_score_val = gcgru_test(model, val_data, data, device)\n",
    "        \n",
    "        \"\"\"\n",
    "        if mrr_val_max-tol < mrr_val:\n",
    "            mrr_val_max = mrr_val\n",
    "            best_epoch = epoch\n",
    "            best_current_embeddings = current_embeddings\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        #print(f'Epoch: {epoch} done')\n",
    "            \n",
    "        \"\"\"\n",
    "        if avgpr_val_max-tol <= avgpr_score_val:\n",
    "            avgpr_val_max = avgpr_score_val\n",
    "            best_H = H.clone()\n",
    "            best_epoch = epoch\n",
    "            best_model = model\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    avgpr_score_test = gcgru_test(model, test_data, data, device)\n",
    "            \n",
    "    if verbose:\n",
    "        print(f'Best Epoch: {best_epoch}')\n",
    "    #print(f'Best Epoch: {best_epoch}')\n",
    "    \n",
    "    return best_model, avgpr_score_test, best_H, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ev_train_single_snapshot(model, data, train_data, val_data, test_data,\\\n",
    "                          optimizer, device='cpu', num_epochs=50, verbose=False):\n",
    "    \n",
    "    mrr_val_max = 0\n",
    "    avgpr_val_max = 0\n",
    "    best_model = model\n",
    "    train_data = train_data.to(device)\n",
    "    best_epoch = -1\n",
    "    \n",
    "    tol = 5e-2\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        ## Note\n",
    "        ## 1. Zero grad the optimizer\n",
    "        ## 2. Compute loss and backpropagate\n",
    "        ## 3. Update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        pred = model(train_data.x, train_data.edge_index, train_data.edge_label_index)\n",
    "        \n",
    "        loss = model.loss(pred, train_data.edge_label.type_as(pred)) #loss to fine tune on current snapshot\n",
    "\n",
    "        loss.backward(retain_graph=True)  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "        log = 'Epoch: {:03d}\\n AVGPR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n MRR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n F1-Score Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n Loss: {}'\n",
    "        avgpr_score_val = ev_test(model, val_data, data, device)\n",
    "        \n",
    "        \"\"\"\n",
    "        if mrr_val_max-tol < mrr_val:\n",
    "            mrr_val_max = mrr_val\n",
    "            besst_epoch = epoch\n",
    "            best_current_embeddings = current_embeddings\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        #print(f'Epoch: {epoch} done')\n",
    "            \n",
    "        \"\"\"\n",
    "        if avgpr_val_max-tol <= avgpr_score_val:\n",
    "            avgpr_val_max = avgpr_score_val\n",
    "            best_epoch = epoch\n",
    "            best_model = model\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    avgpr_score_test = ev_test(model, test_data, data, device)\n",
    "            \n",
    "    if verbose:\n",
    "        print(f'Best Epoch: {best_epoch}')\n",
    "    #print(f'Best Epoch: {best_epoch}')\n",
    "    \n",
    "    return best_model, avgpr_score_test, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(snapshots, hidden_conv1, hidden_conv2, update='gru', device='cpu'):\n",
    "    \"\"\"\n",
    "        Train and evaluate all the baselines in the live update setting\n",
    "    \"\"\"\n",
    "    num_snap = len(snapshots)\n",
    "    input_channels = snapshots[0].x.size(1)\n",
    "    num_nodes = snapshots[0].x.size(0)\n",
    "    last_embeddings = [torch.Tensor([[0 for i in range(hidden_conv1)] for j in range(num_nodes)]),\\\n",
    "                                    torch.Tensor([[0 for i in range(hidden_conv2)] for j in range(num_nodes)])]\n",
    "    \n",
    "    #TODO: rifare per ogni modello\n",
    "    ro_avgpr_test_singles = []\n",
    "    gcgru_avgpr_test_singles = []\n",
    "    evo_avgpr_test_singles = []\n",
    "    evh_avgpr_test_singles = []\n",
    "    \n",
    "    roland = T3GNN(input_channels, 2, hidden_conv1, dropout=0.3, update=update)\n",
    "    rolopt = torch.optim.Adam(params=roland.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    roland.reset_parameters()\n",
    "    \n",
    "    gcgru = T3GConvGRU(input_channels, hidden_conv2)\n",
    "    gcgruopt = torch.optim.Adam(params=gcgru.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    gcgru.reset_parameters()\n",
    "    H = None\n",
    "    \n",
    "    evh = T3EvolveGCNH(num_nodes, input_channels)\n",
    "    evhopt = torch.optim.Adam(params=evh.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    evh.reset_parameters()\n",
    "    \n",
    "    evo = T3EvolveGCNO(input_channels)\n",
    "    evopt = torch.optim.Adam(params=evo.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    evo.reset_parameters()\n",
    "    \n",
    "    for i in range(num_snap-1):\n",
    "        #CREATE TRAIN + VAL + TEST SET FOR THE CURRENT SNAP\n",
    "        snapshot = copy.deepcopy(snapshots[i])\n",
    "        num_current_edges = len(snapshot.edge_index[0])\n",
    "        transform = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "        train_data, _, val_data = transform(snapshot)\n",
    "        test_data = copy.deepcopy(snapshots[i+1])\n",
    "        \n",
    "        #NEGATIVE SET: EDGES CLOSED IN THE PAST BUT NON IN THE CURRENT TEST SET\n",
    "        past_edges = set(zip([int(e) for e in snapshot.edge_index[0]],\\\n",
    "                             [int(e) for e in snapshot.edge_index[1]]))\n",
    "        current_edges = set(zip([int(e) for e in test_data.edge_index[0]],\\\n",
    "                             [int(e) for e in test_data.edge_index[1]]))\n",
    "        \n",
    "        negative_edges = list(past_edges.difference(current_edges))[:test_data.edge_index.size(1)]\n",
    "        future_neg_edge_index = torch.Tensor([[a[0] for a in negative_edges],\\\n",
    "                                                 [a[1] for a in negative_edges]]).long()\n",
    "        \n",
    "        num_pos_edge = test_data.edge_index.size(1)\n",
    "        num_neg_edge = future_neg_edge_index.size(1)\n",
    "        test_data.edge_label = torch.Tensor(np.array([1 for i in range(num_pos_edge)] + [0 for i in range(num_neg_edge)]))\n",
    "        test_data.edge_label_index = torch.cat([test_data.edge_index, future_neg_edge_index], dim=-1)\n",
    "        \n",
    "        #TRAIN AND TEST THE MODELS FOR THE CURRENT SNAP\n",
    "        roland, rolopt, ro_avgpr_test, last_embeddings =\\\n",
    "            roland_train_single_snapshot(roland, snapshot, train_data, val_data, test_data, i,\\\n",
    "                                  last_embeddings, rolopt)\n",
    "        \n",
    "        gcgru, gcgru_avgpr_test, H, gcgruopt =\\\n",
    "            gcgru_train_single_snapshot(gcgru, snapshot, train_data, val_data, test_data, gcgruopt, H)\n",
    "        \n",
    "        evo, evo_avgpr_test, evopt =\\\n",
    "            ev_train_single_snapshot(evo, snapshot, train_data, val_data, test_data, evopt)\n",
    "        \n",
    "        evh, evh_avgpr_test, evhopt =\\\n",
    "            ev_train_single_snapshot(evh, snapshot, train_data, val_data, test_data, evhopt)\n",
    "        \n",
    "        \n",
    "        #SAVE AND DISPLAY EVALUATION\n",
    "        print(f'Snapshot: {i}\\n\\tT3GNN AVGPR Test: {ro_avgpr_test}')\n",
    "        print(f'\\tGCGRU AVGPR Test: {gcgru_avgpr_test}')\n",
    "        print(f'\\tEvolveGCN-O AVGPR Test: {evo_avgpr_test}')\n",
    "        print(f'\\tEvolveGCN-H AVGPR Test: {evh_avgpr_test}')\n",
    "        \n",
    "        ro_avgpr_test_singles.append(ro_avgpr_test)\n",
    "        gcgru_avgpr_test_singles.append(gcgru_avgpr_test)\n",
    "        evo_avgpr_test_singles.append(evo_avgpr_test)\n",
    "        evh_avgpr_test_singles.append(evh_avgpr_test)\n",
    "        \n",
    "    ro_avgpr_test_all = sum(ro_avgpr_test_singles)/len(ro_avgpr_test_singles)\n",
    "    gcgru_avgpr_test_all = sum(gcgru_avgpr_test_singles)/len(gcgru_avgpr_test_singles)\n",
    "    evo_avgpr_test_all = sum(evo_avgpr_test_singles)/len(evo_avgpr_test_singles)\n",
    "    evh_avgpr_test_all = sum(evh_avgpr_test_singles)/len(evh_avgpr_test_singles)\n",
    "    \n",
    "    print(f'T3GNN AVGPR over time: Test: {ro_avgpr_test_all}')\n",
    "    print(f'GCGRU AVGPR over time: Test: {gcgru_avgpr_test_all}')\n",
    "    print(f'EvolveGCN-O AVGPR over time: Test: {evo_avgpr_test_all}')\n",
    "    print(f'EvolveGCN-H AVGPR over time: Test: {evh_avgpr_test_all}')\n",
    "    \n",
    "    return ro_avgpr_test_singles, gcgru_avgpr_test_singles, evo_avgpr_test_singles, evh_avgpr_test_singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97829012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_roland(snapshots, hidden_conv1, hidden_conv2, update='gru', device='cpu',\\\n",
    "                 add_self_loops=False, skip_connections=False, content_mlp=False,\\\n",
    "                 shuffle_node_features=False, random_graph=False):\n",
    "    \"\"\"\n",
    "        Train and evaluate T3GNN with historical negative edges in the live update setting\n",
    "    \"\"\"\n",
    "    num_snap = len(snapshots)\n",
    "    input_channels = snapshots[0].x.size(1)\n",
    "    num_nodes = snapshots[0].x.size(0)\n",
    "    last_embeddings = [torch.Tensor([[0 for i in range(hidden_conv1)] for j in range(num_nodes)]),\\\n",
    "                                    torch.Tensor([[0 for i in range(hidden_conv2)] for j in range(num_nodes)])]\n",
    " \n",
    "    avgpr_test_singles = []\n",
    "    \n",
    "    hidden_dimension = hidden_conv1\n",
    "    \n",
    "    roland = T3GNN(input_channels, 2, hidden_dimension, dropout=0.3, update=update,\\\n",
    "                  add_self_loops = add_self_loops, skip_connections=skip_connections, content_mlp=content_mlp)\n",
    "    rolopt = torch.optim.Adam(params=roland.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    roland.reset_parameters()\n",
    "    \n",
    "    for i in range(num_snap-1):\n",
    "        #CREATE TRAIN + VAL + TEST SET FOR THE CURRENT SNAP\n",
    "        snapshot = copy.deepcopy(snapshots[i])\n",
    "        if shuffle_node_features:\n",
    "            snapshot.x, _ = shuffle_node(snapshot.x)\n",
    "        num_current_edges = len(snapshot.edge_index[0])\n",
    "        transform = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "        train_data, _, val_data = transform(snapshot)\n",
    "        if random_graph:\n",
    "            density = snapshot.edge_index.size(0) / (num_nodes * (num_nodes-1))\n",
    "            train_data.edge_index = erdos_renyi_graph(num_nodes, density, directed=True)\n",
    "        test_data = copy.deepcopy(snapshots[i+1])\n",
    "        \n",
    "        #NEGATIVE SET: EDGES CLOSED IN THE PAST BUT NON IN THE CURRENT TEST SET\n",
    "        past_edges = set(zip([int(e) for e in snapshot.edge_index[0]],\\\n",
    "                             [int(e) for e in snapshot.edge_index[1]]))\n",
    "        current_edges = set(zip([int(e) for e in test_data.edge_index[0]],\\\n",
    "                             [int(e) for e in test_data.edge_index[1]]))\n",
    "        \n",
    "        negative_edges = list(past_edges.difference(current_edges))[:test_data.edge_index.size(1)]\n",
    "        future_neg_edge_index = torch.Tensor([[a[0] for a in negative_edges],\\\n",
    "                                                 [a[1] for a in negative_edges]]).long()\n",
    "        \n",
    "        num_pos_edge = test_data.edge_index.size(1)\n",
    "        num_neg_edge = future_neg_edge_index.size(1)\n",
    "        test_data.edge_label = torch.Tensor(np.array([1 for i in range(num_pos_edge)] + [0 for i in range(num_neg_edge)]))\n",
    "        test_data.edge_label_index = torch.cat([test_data.edge_index, future_neg_edge_index], dim=-1)\n",
    "        \n",
    "        #TRAIN AND TEST THE MODEL FOR THE CURRENT SNAP\n",
    "        roland, rolopt, avgpr_test, last_embeddings =\\\n",
    "            roland_train_single_snapshot(roland, snapshot, train_data, val_data, test_data, i,\\\n",
    "                                  last_embeddings, rolopt)\n",
    "        \n",
    "        \n",
    "        #SAVE AND DISPLAY EVALUATION\n",
    "        print(f'Snapshot: {i}\\n\\tT3GNN AVGPR Test: {avgpr_test}')\n",
    "        avgpr_test_singles.append(avgpr_test)\n",
    "        \n",
    "    avgpr_test_all = sum(avgpr_test_singles)/len(avgpr_test_singles)\n",
    "    \n",
    "    print(f'T3GNN AVGPR over time Test: {avgpr_test_all}')\n",
    "    \n",
    "    return avgpr_test_singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60538be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(snapshots, hidden_conv1, hidden_conv2, update='gru', device='cpu'):\n",
    "    \"\"\"\n",
    "        Train and evaluate T3GNN with historical negative edges in the live update setting\n",
    "    \"\"\"\n",
    "    num_snap = len(snapshots)\n",
    "    input_channels = snapshots[0].x.size(1)\n",
    "    num_nodes = snapshots[0].x.size(0)\n",
    "    last_embeddings = [torch.Tensor([[0 for i in range(hidden_conv1)] for j in range(num_nodes)]),\\\n",
    "                                    torch.Tensor([[0 for i in range(hidden_conv2)] for j in range(num_nodes)])]\n",
    " \n",
    "    avgpr_test_singles = []\n",
    "    \n",
    "    hidden_dimension = hidden_conv1\n",
    "    \n",
    "    roland = T3MLP(input_channels, 2, hidden_dimension, dropout=0.3, update=update)\n",
    "    rolopt = torch.optim.Adam(params=roland.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    roland.reset_parameters()\n",
    "    \n",
    "    for i in range(num_snap-1):\n",
    "        #CREATE TRAIN + VAL + TEST SET FOR THE CURRENT SNAP\n",
    "        snapshot = copy.deepcopy(snapshots[i])\n",
    "        num_current_edges = len(snapshot.edge_index[0])\n",
    "        transform = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "        train_data, _, val_data = transform(snapshot)\n",
    "        test_data = copy.deepcopy(snapshots[i+1])\n",
    "        \n",
    "        #NEGATIVE SET: EDGES CLOSED IN THE PAST BUT NON IN THE CURRENT TEST SET\n",
    "        past_edges = set(zip([int(e) for e in snapshot.edge_index[0]],\\\n",
    "                             [int(e) for e in snapshot.edge_index[1]]))\n",
    "        current_edges = set(zip([int(e) for e in test_data.edge_index[0]],\\\n",
    "                             [int(e) for e in test_data.edge_index[1]]))\n",
    "        \n",
    "        negative_edges = list(past_edges.difference(current_edges))[:test_data.edge_index.size(1)]\n",
    "        future_neg_edge_index = torch.Tensor([[a[0] for a in negative_edges],\\\n",
    "                                                 [a[1] for a in negative_edges]]).long()\n",
    "        \n",
    "        num_pos_edge = test_data.edge_index.size(1)\n",
    "        num_neg_edge = future_neg_edge_index.size(1)\n",
    "        test_data.edge_label = torch.Tensor(np.array([1 for i in range(num_pos_edge)] + [0 for i in range(num_neg_edge)]))\n",
    "        test_data.edge_label_index = torch.cat([test_data.edge_index, future_neg_edge_index], dim=-1)\n",
    "        \n",
    "        #TRAIN AND TEST THE MODEL FOR THE CURRENT SNAP\n",
    "        roland, rolopt, avgpr_test, last_embeddings =\\\n",
    "            roland_train_single_snapshot(roland, snapshot, train_data, val_data, test_data, i,\\\n",
    "                                  last_embeddings, rolopt)\n",
    "        \n",
    "        \n",
    "        #SAVE AND DISPLAY EVALUATION\n",
    "        print(f'Snapshot: {i}\\n\\tT3GNN AVGPR Test: {avgpr_test}')\n",
    "        avgpr_test_singles.append(avgpr_test)\n",
    "        \n",
    "    avgpr_test_all = sum(avgpr_test_singles)/len(avgpr_test_singles)\n",
    "    \n",
    "    print(f'T3MLP AVGPR over time Test: {avgpr_test_all}')\n",
    "    \n",
    "    return avgpr_test_singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5492d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_bank(snapshots):\n",
    "    \"\"\"\n",
    "       Edgebank baseline\n",
    "    \"\"\"\n",
    "    num_snap = len(snapshots)\n",
    "    num_nodes = snapshots[0].x.size(0)\n",
    " \n",
    "    avgpr_test_singles = []\n",
    "    \n",
    "    edge_bank = nx.DiGraph()\n",
    "    \n",
    "    for i in range(num_snap-1):\n",
    "        #CREATE TRAIN + VAL + TEST SET FOR THE CURRENT SNAP\n",
    "        snapshot = copy.deepcopy(snapshots[i])\n",
    "        num_current_edges = len(snapshot.edge_index[0])\n",
    "        transform = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "        train_data, _, val_data = transform(snapshot)\n",
    "        test_data = copy.deepcopy(snapshots[i+1])\n",
    "        \n",
    "        #NEGATIVE SET: EDGES CLOSED IN THE PAST BUT NON IN THE CURRENT TEST SET\n",
    "        past_edges = set(zip([int(e) for e in snapshot.edge_index[0]],\\\n",
    "                             [int(e) for e in snapshot.edge_index[1]]))\n",
    "        current_edges = set(zip([int(e) for e in test_data.edge_index[0]],\\\n",
    "                             [int(e) for e in test_data.edge_index[1]]))\n",
    "        \n",
    "        negative_edges = list(past_edges.difference(current_edges))[:test_data.edge_index.size(1)]\n",
    "        future_neg_edge_index = torch.Tensor([[a[0] for a in negative_edges],\\\n",
    "                                                 [a[1] for a in negative_edges]]).long()\n",
    "        \n",
    "        num_pos_edge = test_data.edge_index.size(1)\n",
    "        num_neg_edge = future_neg_edge_index.size(1)\n",
    "        test_data.edge_label = torch.Tensor(np.array([1 for i in range(num_pos_edge)] + [0 for i in range(num_neg_edge)]))\n",
    "        test_data.edge_label_index = torch.cat([test_data.edge_index, future_neg_edge_index], dim=-1)\n",
    "        \n",
    "        #TRAIN AND TEST THE MODEL FOR THE CURRENT SNAP\n",
    "        #to networkx train_data, then add to existing edges, then pred with an if\n",
    "        to_add_edges = list(to_networkx(train_data).edges())\n",
    "        edge_bank.add_edges_from(to_add_edges)\n",
    "        \n",
    "        pred_cont = []\n",
    "        for src,dst in zip(test_data.edge_label_index[0].detach().numpy(),test_data.edge_label_index[1].detach().numpy()):\n",
    "            pred_cont.append(1 if edge_bank.has_edge(src,dst) else 0)\n",
    "        label = test_data.edge_label.cpu().detach().numpy()\n",
    "        avgpr_test = average_precision_score(label, pred_cont)\n",
    "        \n",
    "        #SAVE AND DISPLAY EVALUATION\n",
    "        print(f'Snapshot: {i}\\n\\tEdgeBank AVGPR Test: {avgpr_test}')\n",
    "        avgpr_test_singles.append(avgpr_test)\n",
    "        \n",
    "    avgpr_test_all = sum(avgpr_test_singles)/len(avgpr_test_singles)\n",
    "    \n",
    "    print(f'EdgeBank AVGPR over time Test: {avgpr_test_all}')\n",
    "    \n",
    "    return avgpr_test_singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_roland_random(snapshots, hidden_conv1, hidden_conv2, update='gru', device='cpu'):\n",
    "    \"\"\"\n",
    "        Train T3GNN with random negative sampling\n",
    "    \"\"\"\n",
    "    num_snap = len(snapshots)\n",
    "    input_channels = snapshots[0].x.size(1)\n",
    "    num_nodes = snapshots[0].x.size(0)\n",
    "    last_embeddings = [torch.Tensor([[0 for i in range(hidden_conv1)] for j in range(num_nodes)]),\\\n",
    "                                    torch.Tensor([[0 for i in range(hidden_conv2)] for j in range(num_nodes)])]\n",
    " \n",
    "    avgpr_test_singles = []\n",
    "    \n",
    "    roland = T3GNN(input_channels, 2, hidden_conv1, dropout=0.3, update=update)\n",
    "    rolopt = torch.optim.Adam(params=roland.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    roland.reset_parameters()\n",
    "    \n",
    "    for i in range(num_snap-1):\n",
    "        #CREATE TRAIN + VAL + TEST SET FOR THE CURRENT SNAP\n",
    "        snapshot = copy.deepcopy(snapshots[i])\n",
    "        num_current_edges = len(snapshot.edge_index[0])\n",
    "        transform = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "        train_data, _, val_data = transform(snapshot)\n",
    "        test_data = copy.deepcopy(snapshots[i+1])\n",
    "        \n",
    "        future_neg_edge_index = negative_sampling(\n",
    "            edge_index=test_data.edge_index, #positive edges\n",
    "            num_nodes=test_data.num_nodes, # number of nodes\n",
    "            num_neg_samples=test_data.edge_index.size(1)) # number of neg_sample equal to number of pos_edges\n",
    "        #edge index ok, edge_label concat, edge_label_index concat\n",
    "        num_pos_edge = test_data.edge_index.size(1)\n",
    "        test_data.edge_label = torch.Tensor(np.array([1 for i in range(num_pos_edge)] + [0 for i in range(num_pos_edge)]))\n",
    "        test_data.edge_label_index = torch.cat([test_data.edge_index, future_neg_edge_index], dim=-1)\n",
    "        \n",
    "        #TRAIN AND TEST THE MODEL FOR THE CURRENT SNAP\n",
    "        roland, rolopt, avgpr_test, last_embeddings =\\\n",
    "            roland_train_single_snapshot(roland, snapshot, train_data, val_data, test_data, i,\\\n",
    "                                  last_embeddings, rolopt)\n",
    "        \n",
    "        \n",
    "        #SAVE AND DISPLAY EVALUATION\n",
    "        print(f'Snapshot: {i}\\n\\tT3GNN random sampling AVGPR Test: {avgpr_test}')\n",
    "        avgpr_test_singles.append(avgpr_test)\n",
    "        \n",
    "    avgpr_test_all = sum(avgpr_test_singles)/len(avgpr_test_singles)\n",
    "    \n",
    "    print(f'T3GNN AVGPR over time Test: {avgpr_test_all}')\n",
    "    \n",
    "    return avgpr_test_singles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd84cad",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "device = torch.device('cuda')\n",
    "torch.manual_seed(41)\n",
    "torch.cuda.manual_seed_all(41)\n",
    "np.random.seed(41)\n",
    "random.seed(41)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f8006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_conv1 = 64\n",
    "hidden_conv2 = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b315df9",
   "metadata": {},
   "source": [
    "## Train on the link prediction task using sentence embedding and network structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9144b4eb",
   "metadata": {},
   "source": [
    "### Self-loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08051a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_selfloops_avgpr = train_roland(snapshots_t, hidden_conv1, hidden_conv2, update='mlp', add_self_loops=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818ec89f",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587de38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_avgpr, gcgru_avgpr, evo_avgpr, evh_avgpr = train_models(snapshots_t, hidden_conv1, hidden_conv2, update='mlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ab178",
   "metadata": {},
   "source": [
    "### Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de2a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_randomsample_avgpr = train_roland_random(snapshots_t, hidden_conv1, hidden_conv2, update='mlp') #random-negative-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c170fd87",
   "metadata": {},
   "source": [
    "### No Self loops, Skip Connections, Content MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a81d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_selfloops_avgpr = train_roland(snapshots_t, hidden_conv1, hidden_conv2, update='mlp', add_self_loops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_skip_avgpr = train_roland(snapshots_t, hidden_conv1, hidden_conv2, update='mlp', skip_connections=True)\n",
    "ro_content_avgpr = train_roland(snapshots_t, hidden_conv1, hidden_conv2, update='mlp', content_mlp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f1d119",
   "metadata": {},
   "source": [
    "### Feature shuffling, T3MLP, EdgeBank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea998fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Node shuffling')\n",
    "ro_shuffling_avgpr = train_roland(snapshots_t, hidden_conv1, hidden_conv2, update='mlp', shuffle_node_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('T3MLP')\n",
    "ro_mlp_avgpr = train_mlp(snapshots_t, hidden_conv1, hidden_conv2, update='mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91646d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EdgeBank')\n",
    "ro_edgebank_avgpr = edge_bank(snapshots_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4cbfb5",
   "metadata": {},
   "source": [
    "### Random Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b37eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_constant_avgpr = train_roland(snapshots_c, hidden_conv1, hidden_conv2, update='mlp') #no-features\n",
    "ro_randomf_avgpr = train_roland(snapshots_ts, hidden_conv1, hidden_conv2, update='mlp') #random_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
