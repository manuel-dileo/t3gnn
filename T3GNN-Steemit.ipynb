{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76e04ce",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d94c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, GRUCell\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import roc_auc_score,average_precision_score\n",
    "\n",
    "import random\n",
    "\n",
    "import bisect \n",
    "\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.transforms import SVDFeatureReduction\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.transforms import RandomLinkSplit,NormalizeFeatures,Constant,OneHotDegree\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import GCNConv,SAGEConv,GATv2Conv, GINConv, Linear\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8b40a",
   "metadata": {},
   "source": [
    "# LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d8f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from steemitdata import get_steemit_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502cf464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snapshots with constant encoder as node features\n",
    "#Snapshots with textual features as node features\n",
    "\n",
    "snapshots_c = get_steemit_dataset(preprocess='constant')\n",
    "snapshots_t = get_steemit_dataset(preprocess='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(snapshots_t)):\n",
    "    torch.save(snapshots_t[i].x, f'steemit-t3gnn-data/{i}_x.pt')\n",
    "    torch.save(snapshots_t[i].edge_index, f'steemit-t3gnn-data/{i}_edge_index.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snapshots with random features as node features\n",
    "snapshots_ts = get_steemit_dataset(preprocess='constant')\n",
    "for snap in snapshots_ts:\n",
    "    snap.x = torch.randn(snap.num_nodes, 384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff34ed04",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9262266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from t3gnn import T3GConvGRU, T3EvolveGCNH, T3EvolveGCNO, T3GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roland_test(model, test_data, data, isnap, device='cpu'):\n",
    "    model.eval()\n",
    "\n",
    "    test_data = test_data.to(device)\n",
    "\n",
    "    h, _ = model(test_data.x, test_data.edge_index, edge_label_index = test_data.edge_label_index, isnap=isnap)\n",
    "    \n",
    "    pred_cont_link = torch.sigmoid(h).cpu().detach().numpy()\n",
    "    \n",
    "    label_link = test_data.edge_label.cpu().detach().numpy()\n",
    "      \n",
    "    avgpr_score_link = average_precision_score(label_link, pred_cont_link)\n",
    "    \n",
    "    return avgpr_score_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ev_test(model, test_data, data, device='cpu'): \n",
    "    model.eval()\n",
    "    test_data = test_data.to(device)\n",
    "    h = model(test_data.x, test_data.edge_index, test_data.edge_label_index)\n",
    "    pred_cont = torch.sigmoid(h).cpu().detach().numpy()\n",
    "    label = test_data.edge_label.cpu().detach().numpy()\n",
    "    avgpr_score = average_precision_score(label, pred_cont)\n",
    "    return avgpr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcgru_test(model, test_data, data, device='cpu'):\n",
    "    model.eval()\n",
    "    test_data = test_data.to(device)\n",
    "    h, _ = model(test_data.x, test_data.edge_index, test_data.edge_label_index)\n",
    "    pred_cont = torch.sigmoid(h).cpu().detach().numpy()\n",
    "    label = test_data.edge_label.cpu().detach().numpy()\n",
    "    avgpr_score = average_precision_score(label, pred_cont)\n",
    "    return avgpr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c87220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "def roland_train_single_snapshot(model, data, train_data, val_data, test_data, isnap,\\\n",
    "                          last_embeddings, optimizer, device='cpu', num_epochs=50, verbose=False):\n",
    "    \n",
    "    avgpr_val_max = 0\n",
    "    best_model = model\n",
    "    train_data = train_data.to(device)\n",
    "    best_epoch = -1\n",
    "    best_current_embeddings = []\n",
    "    \n",
    "    avgpr_trains = []\n",
    "    #avgpr_vals = []\n",
    "    avgpr_tests = []\n",
    "    \n",
    "    tol = 1\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        ## Note\n",
    "        ## 1. Zero grad the optimizer\n",
    "        ## 2. Compute loss and backpropagate\n",
    "        ## 3. Update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred,\\\n",
    "        current_embeddings =\\\n",
    "            model(train_data.x, train_data.edge_index, edge_label_index = train_data.edge_label_index,\\\n",
    "                  isnap=isnap, previous_embeddings=last_embeddings)\n",
    "        \n",
    "        loss = model.loss(pred, train_data.edge_label.type_as(pred)) #loss to fine tune on current snapshot\n",
    "\n",
    "        loss.backward(retain_graph=True)  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "        log = 'Epoch: {:03d}\\n AVGPR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n MRR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n F1-Score Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n Loss: {}'\n",
    "        avgpr_score_val  = roland_test(model, val_data, data, isnap, device)\n",
    "        \n",
    "        #avgpr_trains.append(avgpr_score_train)\n",
    "        #avgpr_vals.append(avgpr_score_val)\n",
    "        #avgpr_tests.append(avgpr_score_test)\n",
    "        \n",
    "        #mrr_trains.append(mrr_train)\n",
    "        #mrr_vals.append(mrr_val)\n",
    "        #mrr_tests.append(mrr_test)\n",
    "        \n",
    "        if avgpr_val_max-tol <= avgpr_score_val:\n",
    "            avgpr_val_max = avgpr_score_val\n",
    "            best_epoch = epoch\n",
    "            best_current_embeddings = current_embeddings\n",
    "            best_model = model\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        \n",
    "    #avgpr_score_train = roland_test(model, train_data, data, isnap, device)\n",
    "    avgpr_score_test = roland_test(model, test_data, data, isnap, device)\n",
    "            \n",
    "    if verbose:\n",
    "        print(f'Best Epoch: {best_epoch}')\n",
    "    #print(f'Best Epoch: {best_epoch}')\n",
    "    \n",
    "    return best_model, optimizer, avgpr_score_test, best_current_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcgru_train_single_snapshot(model, data, train_data, val_data, test_data,\\\n",
    "                          optimizer, H=None, device='cpu', num_epochs=50, verbose=False):\n",
    "    \n",
    "    mrr_val_max = 0\n",
    "    avgpr_val_max = 0\n",
    "    best_model = model\n",
    "    train_data = train_data.to(device)\n",
    "    best_epoch = -1\n",
    "    \n",
    "    tol = 5e-2\n",
    "    \n",
    "    best_H = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        ## Note\n",
    "        ## 1. Zero grad the optimizer\n",
    "        ## 2. Compute loss and backpropagate\n",
    "        ## 3. Update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #H = None\n",
    "            \n",
    "        pred, H = model(train_data.x, train_data.edge_index, train_data.edge_label_index, H)\n",
    "        \n",
    "        loss = model.loss(pred, train_data.edge_label.type_as(pred)) #loss to fine tune on current snapshot\n",
    "\n",
    "        loss.backward(retain_graph=True)  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "        log = 'Epoch: {:03d}\\n AVGPR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n MRR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n F1-Score Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n Loss: {}'\n",
    "        avgpr_score_val = gcgru_test(model, val_data, data, device)\n",
    "        \n",
    "        \"\"\"\n",
    "        if mrr_val_max-tol < mrr_val:\n",
    "            mrr_val_max = mrr_val\n",
    "            best_epoch = epoch\n",
    "            best_current_embeddings = current_embeddings\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        #print(f'Epoch: {epoch} done')\n",
    "            \n",
    "        \"\"\"\n",
    "        if avgpr_val_max-tol <= avgpr_score_val:\n",
    "            avgpr_val_max = avgpr_score_val\n",
    "            best_H = H.clone()\n",
    "            best_epoch = epoch\n",
    "            best_model = model\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    avgpr_score_test = gcgru_test(model, test_data, data, device)\n",
    "            \n",
    "    if verbose:\n",
    "        print(f'Best Epoch: {best_epoch}')\n",
    "    #print(f'Best Epoch: {best_epoch}')\n",
    "    \n",
    "    return best_model, avgpr_score_test, best_H, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ev_train_single_snapshot(model, data, train_data, val_data, test_data,\\\n",
    "                          optimizer, device='cpu', num_epochs=50, verbose=False):\n",
    "    \n",
    "    mrr_val_max = 0\n",
    "    avgpr_val_max = 0\n",
    "    best_model = model\n",
    "    train_data = train_data.to(device)\n",
    "    best_epoch = -1\n",
    "    \n",
    "    tol = 5e-2\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        ## Note\n",
    "        ## 1. Zero grad the optimizer\n",
    "        ## 2. Compute loss and backpropagate\n",
    "        ## 3. Update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        pred = model(train_data.x, train_data.edge_index, train_data.edge_label_index)\n",
    "        \n",
    "        loss = model.loss(pred, train_data.edge_label.type_as(pred)) #loss to fine tune on current snapshot\n",
    "\n",
    "        loss.backward(retain_graph=True)  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "        log = 'Epoch: {:03d}\\n AVGPR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n MRR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n F1-Score Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n Loss: {}'\n",
    "        avgpr_score_val = ev_test(model, val_data, data, device)\n",
    "        \n",
    "        \"\"\"\n",
    "        if mrr_val_max-tol < mrr_val:\n",
    "            mrr_val_max = mrr_val\n",
    "            besst_epoch = epoch\n",
    "            best_current_embeddings = current_embeddings\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        #print(f'Epoch: {epoch} done')\n",
    "            \n",
    "        \"\"\"\n",
    "        if avgpr_val_max-tol <= avgpr_score_val:\n",
    "            avgpr_val_max = avgpr_score_val\n",
    "            best_epoch = epoch\n",
    "            best_model = model\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    avgpr_score_test = ev_test(model, test_data, data, device)\n",
    "            \n",
    "    if verbose:\n",
    "        print(f'Best Epoch: {best_epoch}')\n",
    "    #print(f'Best Epoch: {best_epoch}')\n",
    "    \n",
    "    return best_model, avgpr_score_test, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(snapshots, hidden_conv1, hidden_conv2, update='gru', device='cpu'):\n",
    "    \"\"\"\n",
    "        Train and evaluate all the baselines in the live update setting\n",
    "    \"\"\"\n",
    "    num_snap = len(snapshots)\n",
    "    input_channels = snapshots[0].x.size(1)\n",
    "    num_nodes = snapshots[0].x.size(0)\n",
    "    last_embeddings = [torch.Tensor([[0 for i in range(hidden_conv1)] for j in range(num_nodes)]),\\\n",
    "                                    torch.Tensor([[0 for i in range(hidden_conv2)] for j in range(num_nodes)])]\n",
    "    \n",
    "    #TODO: rifare per ogni modello\n",
    "    ro_avgpr_test_singles = []\n",
    "    gcgru_avgpr_test_singles = []\n",
    "    evo_avgpr_test_singles = []\n",
    "    evh_avgpr_test_singles = []\n",
    "    \n",
    "    roland = T3GNN(input_channels, 2, hidden_conv1, dropout=0.3, update=update)\n",
    "    rolopt = torch.optim.Adam(params=roland.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    roland.reset_parameters()\n",
    "    \n",
    "    gcgru = T3GConvGRU(input_channels, hidden_conv2)\n",
    "    gcgruopt = torch.optim.Adam(params=gcgru.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    gcgru.reset_parameters()\n",
    "    H = None\n",
    "    \n",
    "    evh = T3EvolveGCNH(num_nodes, input_channels)\n",
    "    evhopt = torch.optim.Adam(params=evh.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    evh.reset_parameters()\n",
    "    \n",
    "    evo = T3EvolveGCNO(input_channels)\n",
    "    evopt = torch.optim.Adam(params=evo.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    evo.reset_parameters()\n",
    "    \n",
    "    for i in range(num_snap-1):\n",
    "        #CREATE TRAIN + VAL + TEST SET FOR THE CURRENT SNAP\n",
    "        snapshot = copy.deepcopy(snapshots[i])\n",
    "        num_current_edges = len(snapshot.edge_index[0])\n",
    "        transform = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "        train_data, _, val_data = transform(snapshot)\n",
    "        test_data = copy.deepcopy(snapshots[i+1])\n",
    "        \n",
    "        #NEGATIVE SET: EDGES CLOSED IN THE PAST BUT NON IN THE CURRENT TEST SET\n",
    "        past_edges = set(zip([int(e) for e in snapshot.edge_index[0]],\\\n",
    "                             [int(e) for e in snapshot.edge_index[1]]))\n",
    "        current_edges = set(zip([int(e) for e in test_data.edge_index[0]],\\\n",
    "                             [int(e) for e in test_data.edge_index[1]]))\n",
    "        \n",
    "        negative_edges = list(past_edges.difference(current_edges))[:test_data.edge_index.size(1)]\n",
    "        future_neg_edge_index = torch.Tensor([[a[0] for a in negative_edges],\\\n",
    "                                                 [a[1] for a in negative_edges]]).long()\n",
    "        \n",
    "        num_pos_edge = test_data.edge_index.size(1)\n",
    "        num_neg_edge = future_neg_edge_index.size(1)\n",
    "        test_data.edge_label = torch.Tensor(np.array([1 for i in range(num_pos_edge)] + [0 for i in range(num_neg_edge)]))\n",
    "        test_data.edge_label_index = torch.cat([test_data.edge_index, future_neg_edge_index], dim=-1)\n",
    "        \n",
    "        #TRAIN AND TEST THE MODELS FOR THE CURRENT SNAP\n",
    "        roland, rolopt, ro_avgpr_test, last_embeddings =\\\n",
    "            roland_train_single_snapshot(roland, snapshot, train_data, val_data, test_data, i,\\\n",
    "                                  last_embeddings, rolopt)\n",
    "        \n",
    "        gcgru, gcgru_avgpr_test, H, gcgruopt =\\\n",
    "            gcgru_train_single_snapshot(gcgru, snapshot, train_data, val_data, test_data, gcgruopt, H)\n",
    "        \n",
    "        evo, evo_avgpr_test, evopt =\\\n",
    "            ev_train_single_snapshot(evo, snapshot, train_data, val_data, test_data, evopt)\n",
    "        \n",
    "        evh, evh_avgpr_test, evhopt =\\\n",
    "            ev_train_single_snapshot(evh, snapshot, train_data, val_data, test_data, evhopt)\n",
    "        \n",
    "        \n",
    "        #SAVE AND DISPLAY EVALUATION\n",
    "        print(f'Snapshot: {i}\\n\\tT3GNN AVGPR Test: {ro_avgpr_test}')\n",
    "        print(f'\\tGCGRU AVGPR Test: {gcgru_avgpr_test}')\n",
    "        print(f'\\tEvolveGCN-O AVGPR Test: {evo_avgpr_test}')\n",
    "        print(f'\\tEvolveGCN-H AVGPR Test: {evh_avgpr_test}')\n",
    "        \n",
    "        ro_avgpr_test_singles.append(ro_avgpr_test)\n",
    "        gcgru_avgpr_test_singles.append(gcgru_avgpr_test)\n",
    "        evo_avgpr_test_singles.append(evo_avgpr_test)\n",
    "        evh_avgpr_test_singles.append(evh_avgpr_test)\n",
    "        \n",
    "    ro_avgpr_test_all = sum(ro_avgpr_test_singles)/len(ro_avgpr_test_singles)\n",
    "    gcgru_avgpr_test_all = sum(gcgru_avgpr_test_singles)/len(gcgru_avgpr_test_singles)\n",
    "    evo_avgpr_test_all = sum(evo_avgpr_test_singles)/len(evo_avgpr_test_singles)\n",
    "    evh_avgpr_test_all = sum(evh_avgpr_test_singles)/len(evh_avgpr_test_singles)\n",
    "    \n",
    "    print(f'T3GNN AVGPR over time: Test: {ro_avgpr_test_all}')\n",
    "    print(f'GCGRU AVGPR over time: Test: {gcgru_avgpr_test_all}')\n",
    "    print(f'EvolveGCN-O AVGPR over time: Test: {evo_avgpr_test_all}')\n",
    "    print(f'EvolveGCN-H AVGPR over time: Test: {evh_avgpr_test_all}')\n",
    "    \n",
    "    return ro_avgpr_test_singles, gcgru_avgpr_test_singles, evo_avgpr_test_singles, evh_avgpr_test_singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97829012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_roland(snapshots, hidden_conv1, hidden_conv2, update='gru', device='cpu'):\n",
    "    \"\"\"\n",
    "        Train and evaluate T3GNN with historical negative edges in the live update setting\n",
    "    \"\"\"\n",
    "    num_snap = len(snapshots)\n",
    "    input_channels = snapshots[0].x.size(1)\n",
    "    num_nodes = snapshots[0].x.size(0)\n",
    "    last_embeddings = [torch.Tensor([[0 for i in range(hidden_conv1)] for j in range(num_nodes)]),\\\n",
    "                                    torch.Tensor([[0 for i in range(hidden_conv2)] for j in range(num_nodes)])]\n",
    " \n",
    "    avgpr_test_singles = []\n",
    "    \n",
    "    roland = T3GNN(input_channels, 2, hidden_conv1, dropout=0.3, update=update)\n",
    "    rolopt = torch.optim.Adam(params=roland.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    roland.reset_parameters()\n",
    "    \n",
    "    for i in range(num_snap-1):\n",
    "        #CREATE TRAIN + VAL + TEST SET FOR THE CURRENT SNAP\n",
    "        snapshot = copy.deepcopy(snapshots[i])\n",
    "        num_current_edges = len(snapshot.edge_index[0])\n",
    "        transform = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "        train_data, _, val_data = transform(snapshot)\n",
    "        test_data = copy.deepcopy(snapshots[i+1])\n",
    "        \n",
    "        #NEGATIVE SET: EDGES CLOSED IN THE PAST BUT NON IN THE CURRENT TEST SET\n",
    "        past_edges = set(zip([int(e) for e in snapshot.edge_index[0]],\\\n",
    "                             [int(e) for e in snapshot.edge_index[1]]))\n",
    "        current_edges = set(zip([int(e) for e in test_data.edge_index[0]],\\\n",
    "                             [int(e) for e in test_data.edge_index[1]]))\n",
    "        \n",
    "        negative_edges = list(past_edges.difference(current_edges))[:test_data.edge_index.size(1)]\n",
    "        future_neg_edge_index = torch.Tensor([[a[0] for a in negative_edges],\\\n",
    "                                                 [a[1] for a in negative_edges]]).long()\n",
    "        \n",
    "        num_pos_edge = test_data.edge_index.size(1)\n",
    "        num_neg_edge = future_neg_edge_index.size(1)\n",
    "        test_data.edge_label = torch.Tensor(np.array([1 for i in range(num_pos_edge)] + [0 for i in range(num_neg_edge)]))\n",
    "        test_data.edge_label_index = torch.cat([test_data.edge_index, future_neg_edge_index], dim=-1)\n",
    "        \n",
    "        #TRAIN AND TEST THE MODEL FOR THE CURRENT SNAP\n",
    "        roland, rolopt, avgpr_test, last_embeddings =\\\n",
    "            roland_train_single_snapshot(roland, snapshot, train_data, val_data, test_data, i,\\\n",
    "                                  last_embeddings, rolopt)\n",
    "        \n",
    "        \n",
    "        #SAVE AND DISPLAY EVALUATION\n",
    "        print(f'Snapshot: {i}\\n\\tT3GNN AVGPR Test: {avgpr_test}')\n",
    "        avgpr_test_singles.append(avgpr_test)\n",
    "        \n",
    "    avgpr_test_all = sum(avgpr_test_singles)/len(avgpr_test_singles)\n",
    "    \n",
    "    print(f'T3GNN AVGPR over time Test: {avgpr_test_all}')\n",
    "    \n",
    "    return avgpr_test_singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_roland_random(snapshots, hidden_conv1, hidden_conv2, update='gru', device='cpu'):\n",
    "    \"\"\"\n",
    "        Train T3GNN with random negative sampling\n",
    "    \"\"\"\n",
    "    num_snap = len(snapshots)\n",
    "    input_channels = snapshots[0].x.size(1)\n",
    "    num_nodes = snapshots[0].x.size(0)\n",
    "    last_embeddings = [torch.Tensor([[0 for i in range(hidden_conv1)] for j in range(num_nodes)]),\\\n",
    "                                    torch.Tensor([[0 for i in range(hidden_conv2)] for j in range(num_nodes)])]\n",
    " \n",
    "    avgpr_test_singles = []\n",
    "    \n",
    "    roland = T3GNN(input_channels, 2, hidden_conv1, dropout=0.3, update=update)\n",
    "    rolopt = torch.optim.Adam(params=roland.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    roland.reset_parameters()\n",
    "    \n",
    "    for i in range(num_snap-1):\n",
    "        #CREATE TRAIN + VAL + TEST SET FOR THE CURRENT SNAP\n",
    "        snapshot = copy.deepcopy(snapshots[i])\n",
    "        num_current_edges = len(snapshot.edge_index[0])\n",
    "        transform = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "        train_data, _, val_data = transform(snapshot)\n",
    "        test_data = copy.deepcopy(snapshots[i+1])\n",
    "        \n",
    "        future_neg_edge_index = negative_sampling(\n",
    "            edge_index=test_data.edge_index, #positive edges\n",
    "            num_nodes=test_data.num_nodes, # number of nodes\n",
    "            num_neg_samples=test_data.edge_index.size(1)) # number of neg_sample equal to number of pos_edges\n",
    "        #edge index ok, edge_label concat, edge_label_index concat\n",
    "        num_pos_edge = test_data.edge_index.size(1)\n",
    "        test_data.edge_label = torch.Tensor(np.array([1 for i in range(num_pos_edge)] + [0 for i in range(num_pos_edge)]))\n",
    "        test_data.edge_label_index = torch.cat([test_data.edge_index, future_neg_edge_index], dim=-1)\n",
    "        \n",
    "        #TRAIN AND TEST THE MODEL FOR THE CURRENT SNAP\n",
    "        roland, rolopt, avgpr_test, last_embeddings =\\\n",
    "            roland_train_single_snapshot(roland, snapshot, train_data, val_data, test_data, i,\\\n",
    "                                  last_embeddings, rolopt)\n",
    "        \n",
    "        \n",
    "        #SAVE AND DISPLAY EVALUATION\n",
    "        print(f'Snapshot: {i}\\n\\tT3GNN random sampling AVGPR Test: {avgpr_test}')\n",
    "        avgpr_test_singles.append(avgpr_test)\n",
    "        \n",
    "    avgpr_test_all = sum(avgpr_test_singles)/len(avgpr_test_singles)\n",
    "    \n",
    "    print(f'T3GNN AVGPR over time Test: {avgpr_test_all}')\n",
    "    \n",
    "    return avgpr_test_singles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd84cad",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "device = torch.device('cuda')\n",
    "torch.manual_seed(41)\n",
    "torch.cuda.manual_seed_all(41)\n",
    "np.random.seed(41)\n",
    "random.seed(41)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f8006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_conv1 = 64\n",
    "hidden_conv2 = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b315df9",
   "metadata": {},
   "source": [
    "### Train on the link prediction task using sentence embedding and network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587de38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_avgpr, gcgru_avgpr, evo_avgpr, evh_avgpr = train_models(snapshots_t, hidden_conv1, hidden_conv2, update='mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52896108",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(0,25)\n",
    "x_ticks_labels = ['2017-01-03','2017-03-14', '2017-05-23', '2017-08-01', '2017-10-10']\n",
    "ticks = [0, 5, 10, 15, 20]\n",
    "plt.plot(x, ro_avgpr, label='T3GNN', linewidth=3)\n",
    "plt.plot(x, evo_avgpr, label='EvolveGCN-O', linewidth=3)\n",
    "plt.plot(x, evh_avgpr, label='EvolveGCN-H', linewidth=3)\n",
    "plt.plot(x, gcgru_avgpr, label='GCRN-GRU', linewidth=3)\n",
    "#plt.xlabel('2-Week', fontsize=15)\n",
    "plt.xlim((0,24))\n",
    "plt.ylabel('AUPRC', fontsize=15)\n",
    "plt.xticks(fontsize=12, ticks= ticks, labels=x_ticks_labels, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "#plt.title('Link prediction performance over time', fontsize=15)\n",
    "plt.legend(fontsize=12)\n",
    "#plt.savefig('results/t3gnn-baselines.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89218219",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# open file in write mode\n",
    "def write_results(fname, listname):\n",
    "    with open(f'results/run2/{fname}.txt', 'w') as fp:\n",
    "        for item in listname:\n",
    "            # write each item on a new line\n",
    "            fp.write(\"%s\\n\" % item)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_results('ro',ro_avgpr)\n",
    "#write_results('gcgru',gcgru_avgpr)\n",
    "#write_results('evo', evo_avgpr)\n",
    "#write_results('evh', evh_avgpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ab178",
   "metadata": {},
   "source": [
    "### Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de2a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_randomsample_avgpr = train_roland_random(snapshots_t, hidden_conv1, hidden_conv2, update='mlp') #random-negative-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f5fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(0,25)\n",
    "x_ticks_labels = ['2017-01-03','2017-03-14', '2017-05-23', '2017-08-01', '2017-10-10']\n",
    "ticks = [0, 5, 10, 15, 20]\n",
    "plt.plot(x, ro_avgpr, label='historical-neg-edges', linewidth=3)\n",
    "plt.plot(x, ro_randomsample_avgpr, label='random-neg-edges', linewidth=3)\n",
    "#plt.xlabel('2-Week', fontsize=15)\n",
    "plt.xlim((0,24))\n",
    "plt.ylabel('AUPRC', fontsize=15)\n",
    "plt.xticks(fontsize=12, labels=x_ticks_labels, ticks=ticks, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "#plt.title('Link prediction performance over time', fontsize=15)\n",
    "plt.legend(fontsize=12)\n",
    "#plt.savefig('results/t3gnn-negative-sampling.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4cbfb5",
   "metadata": {},
   "source": [
    "### Random Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b37eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_constant_avgpr = train_roland(snapshots_c, hidden_conv1, hidden_conv2, update='mlp') #no-features\n",
    "ro_randomf_avgpr = train_roland(snapshots_ts, hidden_conv1, hidden_conv2, update='mlp') #random_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b37e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(0,25)\n",
    "x_ticks_labels = ['2017-01-03','2017-03-14', '2017-05-23', '2017-08-01', '2017-10-10']\n",
    "ticks = [0, 5, 10, 15, 20]\n",
    "plt.plot(x, ro_avgpr, label='Text-features', linewidth=3)\n",
    "plt.plot(x, ro_constant_avgpr, label='Random-features', linewidth=3)\n",
    "plt.plot(x, ro_randomf_avgpr, label='Constant-features', linewidth=3)\n",
    "#plt.xlabel('2-Week', fontsize=15)\n",
    "plt.xlim((0,24))\n",
    "plt.ylabel('AUPRC', fontsize=15)\n",
    "plt.xticks(fontsize=12, labels=x_ticks_labels, ticks=ticks, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "#plt.title('Link prediction performance over time', fontsize=15)\n",
    "plt.legend(fontsize=12)\n",
    "#plt.savefig('results/t3gnn-random-features.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f91f5b",
   "metadata": {},
   "source": [
    "#### Dataset stat plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_op = [\n",
    "    191712,\n",
    "    174692,\n",
    "    156561,\n",
    "    141733,\n",
    "    130279,\n",
    "    181194,\n",
    "    135637,\n",
    "    133169,\n",
    "    174483,\n",
    "    289970,\n",
    "    341374,\n",
    "    448947,\n",
    "    552799,\n",
    "    411647,\n",
    "    337296,\n",
    "    298362,\n",
    "    269092,\n",
    "    270818,\n",
    "    243382,\n",
    "    235857,\n",
    "    190407,\n",
    "    199524,\n",
    "    222980,\n",
    "    217708,\n",
    "    234757\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,25),[e.edge_index.size(1) for e in snapshots_c[1:]], label='transaction_op', linewidth=7)\n",
    "plt.plot(range(0,25),comment_op, label='comment_op', linewidth=7)\n",
    "x_ticks_labels = ['2017-01-03','2017-03-14', '2017-05-23', '2017-08-01', '2017-10-10']\n",
    "ticks = [0, 5, 10, 15, 20]\n",
    "plt.yscale('log')\n",
    "#plt.xlabel('2-Week',fontsize=15)\n",
    "plt.ylabel('Count',fontsize=15)\n",
    "plt.xticks(fontsize=12, labels=x_ticks_labels, ticks=ticks, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlim(0,24)\n",
    "plt.legend(fontsize=15)\n",
    "#plt.title('Number of operations per 2-week')\n",
    "#plt.savefig('results/operations-wide20-notitle.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
