{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76e04ce",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d94c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, GRUCell\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import roc_auc_score,average_precision_score\n",
    "\n",
    "import random\n",
    "\n",
    "import bisect \n",
    "\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.transforms import SVDFeatureReduction\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.transforms import RandomLinkSplit,NormalizeFeatures,Constant,OneHotDegree\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import GCNConv,SAGEConv,GATv2Conv, GINConv, Linear\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8b40a",
   "metadata": {},
   "source": [
    "# LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d8f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from steemitdata import get_steemit_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502cf464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snapshots with constant encoder as node features\n",
    "#Snapshots with textual features as node features\n",
    "\n",
    "snapshots_c = get_steemit_dataset(preprocess='constant')\n",
    "snapshots_t = get_steemit_dataset(preprocess='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(snapshots_t)):\n",
    "    torch.save(snapshots_t[i].x, f'steemit-t3gnn-data/{i}_x.pt')\n",
    "    torch.save(snapshots_t[i].edge_index, f'steemit-t3gnn-data/{i}_edge_index.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snapshots with random features as node features\n",
    "snapshots_ts = get_steemit_dataset(preprocess='constant')\n",
    "for snap in snapshots_ts:\n",
    "    snap.x = torch.randn(snap.num_nodes, 384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff34ed04",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9262266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from t3gnn import T3GNNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data, data, isnap, device='cpu'):\n",
    "    model.eval()\n",
    "\n",
    "    test_data = test_data.to(device)\n",
    "\n",
    "    h, _ = model(test_data.x, test_data.edge_index, edge_label_index = test_data.edge_label_index, isnap=isnap)\n",
    "    \n",
    "    pred_cont_link = torch.sigmoid(h).cpu().detach().numpy()\n",
    "    \n",
    "    label_link = test_data.edge_label.cpu().detach().numpy()\n",
    "      \n",
    "    avgpr_score_link = average_precision_score(label_link, pred_cont_link)\n",
    "    \n",
    "    return avgpr_score_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c87220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "def train_single_snapshot(model, data, train_data, val_data, test_data, isnap,\\\n",
    "                          last_embeddings, optimizer, device='cpu', num_epochs=50, verbose=False):\n",
    "    \n",
    "    avgpr_val_max = 0\n",
    "    best_model = model\n",
    "    train_data = train_data.to(device)\n",
    "    best_epoch = -1\n",
    "    best_current_embeddings = []\n",
    "    \n",
    "    avgpr_trains = []\n",
    "    #avgpr_vals = []\n",
    "    avgpr_tests = []\n",
    "    \n",
    "    tol = 1\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        ## Note\n",
    "        ## 1. Zero grad the optimizer\n",
    "        ## 2. Compute loss and backpropagate\n",
    "        ## 3. Update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred,\\\n",
    "        current_embeddings =\\\n",
    "            model(train_data.x, train_data.edge_index, edge_label_index = train_data.edge_label_index,\\\n",
    "                  isnap=isnap, previous_embeddings=last_embeddings)\n",
    "        \n",
    "        loss = model.loss(pred, train_data.edge_label.type_as(pred)) #loss to fine tune on current snapshot\n",
    "\n",
    "        loss.backward(retain_graph=True)  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "        log = 'Epoch: {:03d}\\n AVGPR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n MRR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n F1-Score Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n Loss: {}'\n",
    "        avgpr_score_val  = test(model, val_data, data, isnap, device)\n",
    "        \n",
    "        #avgpr_trains.append(avgpr_score_train)\n",
    "        #avgpr_vals.append(avgpr_score_val)\n",
    "        #avgpr_tests.append(avgpr_score_test)\n",
    "        \n",
    "        #mrr_trains.append(mrr_train)\n",
    "        #mrr_vals.append(mrr_val)\n",
    "        #mrr_tests.append(mrr_test)\n",
    "        \n",
    "        if avgpr_val_max-tol <= avgpr_score_val:\n",
    "            avgpr_val_max = avgpr_score_val\n",
    "            best_epoch = epoch\n",
    "            best_current_embeddings = current_embeddings\n",
    "            best_model = model\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        \n",
    "    avgpr_score_train = test(model, train_data, data, isnap, device)\n",
    "    avgpr_score_test = test(model, test_data, data, isnap, device)\n",
    "            \n",
    "    if verbose:\n",
    "        print(f'Best Epoch: {best_epoch}')\n",
    "    #print(f'Best Epoch: {best_epoch}')\n",
    "    \n",
    "    return best_model, optimizer, avgpr_score_train, avgpr_score_test, best_current_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_roland(snapshots, hidden_conv1, hidden_conv2, update='gru', device='cpu'):\n",
    "    num_snap = len(snapshots)\n",
    "    input_channels = snapshots[0].x.size(1)\n",
    "    num_nodes = snapshots[0].x.size(0)\n",
    "    last_embeddings = [torch.Tensor([[0 for i in range(hidden_conv1)] for j in range(num_nodes)]),\\\n",
    "                                    torch.Tensor([[0 for i in range(hidden_conv2)] for j in range(num_nodes)])]\n",
    "    avgpr_train_singles = []\n",
    "    avgpr_test_singles = []\n",
    "    mrr_train_singles = []\n",
    "    mrr_test_singles = []\n",
    "    \n",
    "    roland = T3GNNLP(input_channels, num_nodes, dropout=0.3, update=update)\n",
    "    rolopt = torch.optim.Adam(params=roland.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    roland.reset_parameters()\n",
    "    \n",
    "    for i in range(num_snap-1):\n",
    "        #CREATE TRAIN + VAL + TEST SET FOR THE CURRENT SNAP\n",
    "        snapshot = copy.deepcopy(snapshots[i])\n",
    "        num_current_edges = len(snapshot.edge_index[0])\n",
    "        transform = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "        train_data, _, val_data = transform(snapshot)\n",
    "        test_data = copy.deepcopy(snapshots[i+1])\n",
    "        \n",
    "        #NEGATIVE SET: EDGES CLOSED IN THE PAST BUT NON IN THE CURRENT TEST SET\n",
    "        past_edges = set(zip([int(e) for e in snapshot.edge_index[0]],\\\n",
    "                             [int(e) for e in snapshot.edge_index[1]]))\n",
    "        current_edges = set(zip([int(e) for e in test_data.edge_index[0]],\\\n",
    "                             [int(e) for e in test_data.edge_index[1]]))\n",
    "        \n",
    "        negative_edges = list(past_edges.difference(current_edges))[:test_data.edge_index.size(1)]\n",
    "        future_neg_edge_index = torch.Tensor([[a[0] for a in negative_edges],\\\n",
    "                                                 [a[1] for a in negative_edges]]).long()\n",
    "        \n",
    "        num_pos_edge = test_data.edge_index.size(1)\n",
    "        num_neg_edge = future_neg_edge_index.size(1)\n",
    "        test_data.edge_label = torch.Tensor(np.array([1 for i in range(num_pos_edge)] + [0 for i in range(num_neg_edge)]))\n",
    "        test_data.edge_label_index = torch.cat([test_data.edge_index, future_neg_edge_index], dim=-1)\n",
    "        \n",
    "        #TRAIN AND TEST THE MODEL FOR THE CURRENT SNAP\n",
    "        roland, rolopt, avgpr_train, avgpr_test, last_embeddings =\\\n",
    "            train_single_snapshot(roland, snapshot, train_data, val_data, test_data, i,\\\n",
    "                                  last_embeddings, rolopt)\n",
    "        \n",
    "        \n",
    "        #SAVE AND DISPLAY EVALUATION\n",
    "        print(f'Snapshot: {i}\\n\\tLinkPre AVGPR Train: {avgpr_train}, Test: {avgpr_test}')\n",
    "        avgpr_train_singles.append(avgpr_train)\n",
    "        avgpr_test_singles.append(avgpr_test)\n",
    "        \n",
    "    avgpr_train_all = sum(avgpr_train_singles)/len(avgpr_train_singles)\n",
    "    avgpr_test_all = sum(avgpr_test_singles)/len(avgpr_test_singles)\n",
    "    \n",
    "    print(f'LinkPre AVGPR over time: Train {avgpr_train_all}, Test: {avgpr_test_all}')\n",
    "    \n",
    "    return roland, avgpr_train_singles, avgpr_test_singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_roland_random(snapshots, hidden_conv1, hidden_conv2, update='gru', device='cpu'):\n",
    "    num_snap = len(snapshots)\n",
    "    input_channels = snapshots[0].x.size(1)\n",
    "    num_nodes = snapshots[0].x.size(0)\n",
    "    last_embeddings = [torch.Tensor([[0 for i in range(hidden_conv1)] for j in range(num_nodes)]),\\\n",
    "                                    torch.Tensor([[0 for i in range(hidden_conv2)] for j in range(num_nodes)])]\n",
    "    avgpr_train_singles = []\n",
    "    avgpr_test_singles = []\n",
    "    mrr_train_singles = []\n",
    "    mrr_test_singles = []\n",
    "    \n",
    "    roland = T3GNNLP(input_channels, num_nodes, dropout=0.3, update=update)\n",
    "    rolopt = torch.optim.Adam(params=roland.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    roland.reset_parameters()\n",
    "    \n",
    "    for i in range(num_snap-1):\n",
    "        #CREATE TRAIN + VAL + TEST SET FOR THE CURRENT SNAP\n",
    "        snapshot = copy.deepcopy(snapshots[i])\n",
    "        num_current_edges = len(snapshot.edge_index[0])\n",
    "        transform = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "        train_data, _, val_data = transform(snapshot)\n",
    "        test_data = copy.deepcopy(snapshots[i+1])\n",
    "        \n",
    "        #NEGATIVE SET: EDGES CLOSED IN THE PAST BUT NON IN THE CURRENT TEST SET\n",
    "        future_neg_edge_index = negative_sampling(\n",
    "            edge_index=test_data.edge_index, #positive edges\n",
    "            num_nodes=test_data.num_nodes, # number of nodes\n",
    "            num_neg_samples=test_data.edge_index.size(1)) # number of neg_sample equal to number of pos_edges\n",
    "        #edge index ok, edge_label concat, edge_label_index concat\n",
    "        num_pos_edge = test_data.edge_index.size(1)\n",
    "        test_data.edge_label = torch.Tensor(np.array([1 for i in range(num_pos_edge)] + [0 for i in range(num_pos_edge)]))\n",
    "        test_data.edge_label_index = torch.cat([test_data.edge_index, future_neg_edge_index], dim=-1)\n",
    "        \n",
    "        #TRAIN AND TEST THE MODEL FOR THE CURRENT SNAP\n",
    "        roland, rolopt, avgpr_train, avgpr_test, last_embeddings =\\\n",
    "            train_single_snapshot(roland, snapshot, train_data, val_data, test_data, i,\\\n",
    "                                  last_embeddings, rolopt)\n",
    "        \n",
    "        \n",
    "        #SAVE AND DISPLAY EVALUATION\n",
    "        print(f'Snapshot: {i}\\n\\tLinkPre AVGPR Train: {avgpr_train}, Test: {avgpr_test}')\n",
    "        avgpr_train_singles.append(avgpr_train)\n",
    "        avgpr_test_singles.append(avgpr_test)\n",
    "        \n",
    "    avgpr_train_all = sum(avgpr_train_singles)/len(avgpr_train_singles)\n",
    "    avgpr_test_all = sum(avgpr_test_singles)/len(avgpr_test_singles)\n",
    "    \n",
    "    print(f'LinkPre AVGPR over time: Train {avgpr_train_all}, Test: {avgpr_test_all}')\n",
    "    \n",
    "    return roland, avgpr_train_singles, avgpr_test_singles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd84cad",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "device = torch.device('cuda')\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f8006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_conv1 = 64\n",
    "hidden_conv2 = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89064c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, avgpr_trains, avgpr_tests_c = train_roland(snapshots_c, hidden_conv1, hidden_conv2, update='mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c12ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, avgpr_trains, avgpr_tests_t = train_roland(snapshots_t, hidden_conv1, hidden_conv2, update='mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcdd5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, avgpr_trains, avgpr_tests_ts = train_roland(snapshots_ts, hidden_conv1, hidden_conv2, update='mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de2a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, avgpr_trains, avgpr_tests_tr = train_roland_random(snapshots_t, hidden_conv1, hidden_conv2, update='mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b91086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "font = {'size'   : 10}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "#plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f5fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(0,25)\n",
    "plt.plot(x, avgpr_tests_c, label='constant', linewidth=3)\n",
    "plt.plot(x, avgpr_tests_t, label='text', linewidth=3)\n",
    "plt.plot(x, avgpr_tests_ts, label='random-feature', linewidth=3)\n",
    "plt.plot(x, avgpr_tests_tr, label='random-sampling', linewidth=3)\n",
    "plt.xlabel('2-Week', fontsize=15)\n",
    "plt.xlim((0,24))\n",
    "plt.ylabel('AUPRC', fontsize=15)\n",
    "plt.title('Link prediction performance over time', fontsize=15)\n",
    "plt.legend()\n",
    "#plt.savefig('linkpre-results-random-feature-sampling15.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_op = [\n",
    "    191712,\n",
    "    174692,\n",
    "    156561,\n",
    "    141733,\n",
    "    130279,\n",
    "    181194,\n",
    "    135637,\n",
    "    133169,\n",
    "    174483,\n",
    "    289970,\n",
    "    341374,\n",
    "    448947,\n",
    "    552799,\n",
    "    411647,\n",
    "    337296,\n",
    "    298362,\n",
    "    269092,\n",
    "    270818,\n",
    "    243382,\n",
    "    235857,\n",
    "    190407,\n",
    "    199524,\n",
    "    222980,\n",
    "    217708,\n",
    "    234757\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,25),[e.edge_index.size(1) for e in snapshots_c[1:]], label='transaction_op', linewidth=7)\n",
    "plt.plot(range(0,25),comment_op, label='comment_op', linewidth=7)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('2-Week')\n",
    "plt.ylabel('Count')\n",
    "plt.xlim(0,24)\n",
    "plt.legend()\n",
    "plt.title('Number of operations per 2-week')\n",
    "#plt.savefig('operations-wide20.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
